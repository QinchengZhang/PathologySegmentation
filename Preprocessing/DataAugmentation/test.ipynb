{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Augmentation import *\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 512) (512, 512)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n(512, 496) (512, 496)\n"
     ]
    }
   ],
   "source": [
    "root_path = 'G:\\TJUZQC\\DataSet\\optic_disc_seg'\n",
    "train_list = open(os.path.join(root_path, 'test_list.txt'))\n",
    "\n",
    "for files_path in train_list.readlines():\n",
    "    img_path, mask_path = files_path.strip().split(' ')\n",
    "    img = Image.open(os.path.join(root_path, img_path))\n",
    "    mask = Image.open(os.path.join(root_path, mask_path))\n",
    "    print(img.size, mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_map_list(num_classes):\n",
    "    \"\"\" Returns the color map for visualizing the segmentation mask,\n",
    "        which can support arbitrary number of classes.\n",
    "    Args:\n",
    "        num_classes: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "    color_map = num_classes * [0, 0, 0]\n",
    "    for i in range(0, num_classes):\n",
    "        j = 0\n",
    "        lab = i\n",
    "        while lab:\n",
    "            color_map[i * 3] |= (((lab >> 0) & 1) << (7 - j))\n",
    "            color_map[i * 3 + 1] |= (((lab >> 1) & 1) << (7 - j))\n",
    "            color_map[i * 3 + 2] |= (((lab >> 2) & 1) << (7 - j))\n",
    "            j += 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colormap = get_color_map_list(2)\n",
    "for name in glob.glob(mask_augment_path + \"*.tif\"):\n",
    "    mask = np.array(Image.open(name))\n",
    "    mask[mask == 255] = 1\n",
    "\n",
    "    mask = Image.fromarray(mask)\n",
    "    mask.convert('P')\n",
    "    mask.putpalette(colormap)\n",
    "    mask.save(name)\n",
    "    # paddingandresize = ApplyOpsWithMask([\n",
    "    #     PaddingOps(100, padding_mode='reflect'),\n",
    "    #     ResizeOps(img.size)\n",
    "    # ])\n",
    "    # transform = RandomChoiceWithMask([\n",
    "    #     # AffineOps(30, fillcolor=0),\n",
    "    #     FlipOps(),\n",
    "    #     MirrorOps(),\n",
    "    #     # RotateOps(30, fill=0),\n",
    "    #     OffsetOps(50),\n",
    "    #     # paddingandresize,\n",
    "    # ])\n",
    "    # img_fliped, mask_fliped = FlipOps()(img, mask)\n",
    "    # img_mirror, mask_mirror = MirrorOps()(img, mask)\n",
    "\n",
    "\n",
    "\n",
    "    # plt.subplot(221)\n",
    "    # plt.imshow(img_new)\n",
    "    # plt.subplot(222)\n",
    "    # plt.imshow(mask_new, cmap='gray')\n",
    "    # plt.subplot(223)\n",
    "    # plt.imshow(img)\n",
    "    # plt.subplot(224)\n",
    "    # plt.imshow(mask, cmap='gray')\n",
    "    # plt.show()\n",
    "    # img_fliped.save(img_augment_path + \"/\" +  os.path.splitext(base_name)[0] + \"_fliped\" + os.path.splitext(base_name)[1])\n",
    "    # mask_fliped.save(mask_augment_path + \"/\" + os.path.splitext(base_name)[0] + \"_fliped\" + os.path.splitext(base_name)[1])\n",
    "    # img_mirror.save(img_augment_path + \"/\" +  os.path.splitext(base_name)[0] + \"_mirrored\" + os.path.splitext(base_name)[1])\n",
    "    # mask_mirror.save(mask_augment_path + \"/\" + os.path.splitext(base_name)[0] + \"_mirrored\" + os.path.splitext(base_name)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.ones(3, 3)\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(img1)\n",
    "plt.subplot(142)\n",
    "plt.imshow(mask1)\n",
    "plt.subplot(143)\n",
    "plt.imshow(img2)\n",
    "plt.subplot(144)\n",
    "plt.imshow(mask2)\n",
    "plt.show()"
   ]
  }
 ]
}